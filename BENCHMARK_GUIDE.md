# Graph RAG Benchmark Guide

This guide explains how to use the enhanced `graph_rag_workflow.py` with built-in LRU cache benchmarking.

## ğŸš€ Features Added

### 1. **Automatic Answer Printing**
- Every query now displays a clear, formatted answer
- Cache hit/miss status is shown
- Response times are tracked automatically

### 2. **Real-time Performance Benchmarking**
- Tracks all queries with precise timing
- Calculates cache hit rate automatically
- Shows time saved by caching
- Estimates cost savings

### 3. **Interactive Statistics**
- Type `stats` anytime to see current performance metrics
- Automatic benchmark report on exit
- All stats saved to log file

## ğŸ“Š Running the Benchmark

### Step 1: Start the Application

```bash
# Make sure Kuzu is running
docker compose up -d

# Run the benchmark workflow
python graph_rag_workflow.py
```

### Step 2: Ask Questions

```
============================================================
ğŸš€ Graph RAG with LRU Cache - Performance Benchmark
============================================================
Type 'exit', 'quit' to end, or 'stats' to see benchmark report.
============================================================

ğŸ“ Logging chat to chat_log.txt

> Which scholars won prizes in Physics?
```

### Step 3: See the Results

**First Query (Cache MISS):**
```
============================================================
â“ QUESTION: Which scholars won prizes in Physics?
============================================================

âŒ Cache Status: MISS

Final Cypher Query:
MATCH (s:Scholar)-[:WON]->(p:Prize) WHERE LOWER(p.category) = 'physics' RETURN s.knownName

--- Running Query and Generating Answer ---

â±ï¸  Total Processing Time: 8.234s
ğŸ“¦ Cache Size: 1/128

ğŸ’¡ ANSWER:
The scholars who won prizes in Physics include Albert Einstein, Marie Curie, 
Niels Bohr, and many others...
```

**Same Query Again (Cache HIT):**
```
============================================================
â“ QUESTION: Which scholars won prizes in Physics?
============================================================

âœ… Cache Status: HIT
âš¡ Response Time: 0.123s
ğŸ“¦ Cache Size: 1/128

ğŸ’¡ ANSWER:
The scholars who won prizes in Physics include Albert Einstein, Marie Curie, 
Niels Bohr, and many others...
```

**Notice the difference:** 8.234s â†’ 0.123s = **67x faster!** ğŸš€

### Step 4: View Statistics

Type `stats` to see current performance:

```
> stats

============================================================
ğŸ“Š CACHE PERFORMANCE BENCHMARK
============================================================
Total Queries:        10
Cache Hits:           5 (50.0%)
Cache Misses:         5 (50.0%)

âš¡ Avg Hit Time:      0.145s
ğŸŒ Avg Miss Time:     7.892s
ğŸš€ Speedup (cached):  54.5x faster

â±ï¸  Total Time Saved:  39.46s
ğŸ’° Estimated Cost Saved: $0.0100
============================================================
```

## ğŸ§ª Example Benchmark Session

Here's a complete example to test cache performance:

```bash
# Run these queries in sequence:

1. Which scholars won prizes in Physics?          # MISS - ~8s
2. Which scholars won prizes in Physics?          # HIT  - ~0.1s
3. Who was affiliated with University of Cambridge? # MISS - ~7s
4. Which scholars won prizes in Physics?          # HIT  - ~0.1s
5. Who was affiliated with University of Cambridge? # HIT  - ~0.1s
6. How many laureates won prizes in Chemistry?    # MISS - ~8s
7. Which scholars won prizes in Physics?          # HIT  - ~0.1s
8. stats                                          # Show report
9. exit                                           # Final report
```

**Expected Results:**
- Total Queries: 7 (excluding 'stats' command)
- Cache Hits: 4 (57%)
- Cache Misses: 3 (43%)
- Total Time: ~23s vs ~56s without cache
- **Time Saved: ~33 seconds (59% reduction)**

## ğŸ“ˆ Understanding the Metrics

### Cache Hit Rate
```
Cache Hits: 5 (50.0%)
```
- **Higher is better** - means cache is being used effectively
- 50%+ is good for diverse queries
- 80%+ is excellent for repeated queries

### Response Times
```
âš¡ Avg Hit Time:  0.145s  (cached queries)
ğŸŒ Avg Miss Time: 7.892s  (new queries)
```
- **Hit time**: Retrieving from cache (very fast)
- **Miss time**: Full pipeline execution (slower)
- **Speedup**: Shows performance multiplier

### Time Saved
```
â±ï¸  Total Time Saved: 39.46s
```
- Calculated as: `(Cache Hits) Ã— (Avg Miss Time)`
- Total time you didn't wait due to caching

### Cost Saved
```
ğŸ’° Estimated Cost Saved: $0.0100
```
- Assumes $0.002 per LLM call
- Each cache hit = one avoided API call

## ğŸ¯ Benchmark Tips

### 1. Test Repeated Queries

Ask the same question multiple times to see cache benefits:

```bash
# First time: 8 seconds
> Which scholars won prizes in Physics?

# Second time: 0.1 seconds
> Which scholars won prizes in Physics?
```

### 2. Test Similar Questions

Slightly different questions are cache misses:

```bash
# Different wording = cache miss
> Which scholars won prizes in Physics?
> Who won Physics prizes?  # Different question, cache miss
```

### 3. Monitor Cache Size

Watch the cache grow:

```
ğŸ“¦ Cache Size: 5/128    # 5 queries cached, 123 slots free
ğŸ“¦ Cache Size: 15/128   # 15 queries cached
ğŸ“¦ Cache Size: 128/128  # Cache full, LRU eviction starts
```

### 4. Test Cache Capacity

Fill the cache to see LRU eviction in action:

```bash
# Ask 130+ unique questions
# Oldest entries will be evicted
# Cache size stays at 128
```

## ğŸ“ Log Files

All sessions are logged to `chat_log.txt`:

```
--- Session started at 2025-01-15T10:30:00 ---

> Which scholars won prizes in Physics?
Cache Status: MISS
...

ğŸ“Š CACHE PERFORMANCE BENCHMARK
Total Queries: 10
Cache Hits: 5 (50.0%)
...

--- Session ended at 2025-01-15T10:45:00 ---
```

## ğŸ”§ Configuration

### Adjust Cache Size

In `graph_rag_workflow.py`, line 320:

```python
lru_cache_manager = LRUDataManager(cache_size=128)  # Default

# For more caching:
lru_cache_manager = LRUDataManager(cache_size=512)

# For less memory usage:
lru_cache_manager = LRUDataManager(cache_size=64)
```

### Customize Benchmark Output

In `BenchmarkStats.get_report()`, modify the report format:

```python
report = [
    "\n" + "="*60,
    "ğŸ“Š MY CUSTOM BENCHMARK",
    f"Hit Rate: {hit_rate:.1f}%",
    # Add your own metrics
]
```

## ğŸ“ Understanding Cache Behavior

### Cache Key Composition

The cache key includes:
1. **Question text** - exact string match
2. **Pruned schema** - relevant graph schema

**Example:**
```python
cache_key = "Which scholars won prizes in Physics?|{'nodes':[...]}"
```

### What Gets Cached

The cache stores:
- **Cypher Query**: The generated and validated query
- **Context**: The graph query results (not the final answer)

This means:
- âœ… Skips expensive Cypher generation (3-7 seconds saved)
- âœ… Skips database query execution (1-2 seconds saved)
- âœ… Still generates fresh answer each time (~0.5 seconds)
- âœ… More flexible for different answer generation strategies

### When Cache Hits Occur

âœ… **Cache HIT** when:
- Exact same question
- Same pruned schema
- Entry still in cache (not evicted)

âŒ **Cache MISS** when:
- Different question wording
- Schema pruned differently
- Entry was evicted (LRU)

### LRU Eviction

When cache is full (128 entries):
1. New entry needs to be stored
2. **Least Recently Used** entry is removed
3. New entry takes its place

## ğŸš€ Performance Expectations

### Typical Results

| Scenario | Time (no cache) | Time (cached) | Speedup |
|----------|-----------------|---------------|---------|
| Simple query | 6-8s | 0.1-0.2s | **40-60x** |
| Complex query | 10-15s | 0.1-0.2s | **70-100x** |
| Aggregation | 8-12s | 0.1-0.2s | **50-80x** |

### Cache Hit Rate by Pattern

| Query Pattern | Expected Hit Rate |
|---------------|-------------------|
| Repeated exact queries | 80-100% |
| Similar questions | 20-40% |
| Diverse questions | 10-30% |
| User sessions | 40-70% |

## ğŸ› Troubleshooting

### Cache Not Hitting

**Problem:** Same question shows MISS every time

**Solutions:**
1. Check if question text is exactly the same (case-sensitive)
2. Verify cache size isn't full: `ğŸ“¦ Cache Size: 128/128`
3. Check if schema pruning is consistent

### Performance Slower Than Expected

**Problem:** Cache hits still taking 1-2 seconds

**Solutions:**
1. Check database connection latency
2. Verify LLM for answer generation (cache doesn't skip this step)
3. Check system resources (CPU, memory)

### Stats Not Updating

**Problem:** `stats` command shows old data

**Solutions:**
1. Make sure you're running the updated `graph_rag_workflow.py`
2. Check that queries are completing successfully
3. Restart the application

## ğŸ“š Next Steps

1. **Run Your Own Benchmarks**: Test with your specific query patterns
2. **Tune Cache Size**: Based on your hit rate and memory constraints
3. **Analyze Logs**: Review `chat_log.txt` for detailed session data
4. **Optimize Queries**: Use benchmarks to identify slow queries

## ğŸ‰ Summary

The enhanced Graph RAG workflow now provides:

âœ… **Clear answer display** - See results immediately  
âœ… **Real-time timing** - Know how fast each query is  
âœ… **Cache statistics** - Understand performance impact  
âœ… **Interactive reports** - Check stats anytime with `stats`  
âœ… **Automatic logging** - All sessions saved to file  

**Start benchmarking and see the cache performance benefits yourself!** ğŸš€

